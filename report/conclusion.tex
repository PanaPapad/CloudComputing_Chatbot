\section{Future work}
\label{sec:FW}

Future work for this project involves the improvement of all pieces that make
up our implementation.

The most obvious candidate is the vector store. Since the LLM provides
responses based on the information we give to it, the better the information
that we give to it the better the responses will be. As such, we can try to
improve the process of storing the documentation in our vector store. This
includes the breaking of files into smaller pieces, removing irrelevant data
from our files such as HTML tags, metadata, or other data that is not
information such as HTML tags for buttons.

Breaking up our files into smaller pieces can also help us in providing more
detailed information. We can also add to our context more information instead
of the most relevant from our query. WE can give it the top three results from
our query.

Finally, we can try and improve our queries into the vector store. We might
have relevant information in our vector store that isn’t brought up because our
query isn’t actually the best for what we are looking for.

The second part of our implementation that we can look into improving is our
LLM. We use a pre-trained model that is provided by OpenAI, this is because
designing and implementing a LLM model is not a easy task. There are multiple
other models that we can use, and we can use these other models to make
comparisons.

The most effective approach would be to use a publicly available model and
train it to better understand the information we give to it. This requires a
lot of time and data not to mention knowledge of Machine Learning.

\section{Conclusions}
\label{sec:conclusions}
