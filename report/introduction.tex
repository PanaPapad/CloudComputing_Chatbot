\section{Introduction}
\label{sec:introduction}

The contemporary surge in the capabilities of generative AI models, exemplified
by GPT, has catalyzed significant advancements.
In this project we make the first steps in developing an AI-powered chatbot
tailored for Fog/Edge emulation tools. We use the Fogify \cite{fogify} tool and
tailor our
chatbot to answer questions about the documentation and API of the Fogify
python library.
A main goal is the design of a user-friendly API
enabling clients to articulate Fog Computing infrastructure requirements.

We leverage prompt engineering and contextual learning, our system manipulates
user queries, and interacts with a Large Language Model (LLM) from the OpenAI
API \cite{openaiapi} to create embeddings and get answers for particular
questions. We
incorporate Fogify as the primary emulation tool, by using its documentation.
This
ensures optimal outcomes during prompt engineering. This project
report highlights the integration of AI technologies for streamlining Fog/Edge
emulation processes.