\section{Introduction}
\label{sec:introduction}
The contemporary surge in the capabilities of generative AI models, exemplified
by GPT, has catalyzed significant advancements. This paper outlines the
development of an AI-powered chatbot tailored for Fog/Edge emulation, propelled
by the synergy of cutting-edge AI models and the critical role played by the
Fogify tool. Central to this initiative is the design of a user-friendly API
enabling clients to articulate Fog Computing infrastructure requirements.
Leveraging prompt engineering and contextual learning, our system refines user
queries, subsequently interfacing with a Large Language Model (LLM) like the
ChatGPT API. The incorporation of Fogify as the primary emulation tool, guided
by its documentation, ensures optimal outcomes during prompt engineering. This
paper highlights the integration of AI technologies for streamlining Fog/Edge
emulation processes.