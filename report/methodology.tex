\section{methodology}
\label{sec:methodology}

\subsection{Terminology}

Chroma DB is an open-source vector store, which provides the tools for building
a knowledge base for LLMs

OpenAi: A service that allows developers to integrate advanced natural language
processing capabilities into their applications

Fogify	is an emulation Framework for modelling, deploying and experimenting
with fog testbeds. Provides a toolset to model complex fog topologies

Python is a high-level programming language known for its readability and
simplicity

LangChain is a framework designed to simplify creation of applications using
large language models (LLMs)

\subsection{Process we followed}
A diagram of a chat

Description automatically generatedWe started our process by extracting the
Fogify documentation. More precisely we read all the documents with extension
.xml, .html, .md, yaml. Then those documents are segmented into chunks of 1000
characters. All those chunks form a list of document chunks.Then we need to
transform this list into vectors. We achieve that by utilizing OpenAI in order
to convert chunks to vector embeddings, those embeddings are stored in Chroma
DB which is used for the persistent storage of the embeddings.After the above
steps our tool is ready for use. More precisely, when the chat receives a user
query, it searches the knowledge base in order to receive most relevant
information (context) the we perform prompt engineering  ( context, user's
question, memory of recent conversation messages between user and AI Model) and
feed the prompy to AI model to get response